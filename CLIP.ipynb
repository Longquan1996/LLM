{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目前的一些局限：\n",
    "# 1、文本局限在77tokens，目前是固定的，因为CLIP的限制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "from docx import Document\n",
    "from io import BytesIO\n",
    "from llama_index.readers.file.docs import DocxReader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pymilvus import MilvusClient, FieldSchema, CollectionSchema, DataType, Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 提取文本\n",
    "def extract_text_with_docxreader(docx_path):\n",
    "    docx_reader = DocxReader()\n",
    "    documents = docx_reader.load_data(docx_path)\n",
    "    for i in range(len(documents)):\n",
    "        documents[i] = documents[i].to_langchain_format()\n",
    "    return documents  # 返回的是 List[Document]，可直接用于 LlamaIndex 等\n",
    "\n",
    "# 2. 提取图片\n",
    "def extract_images_as_pil(docx_path, output_folder=\"images\"):\n",
    "    images = []\n",
    "    with ZipFile(docx_path, 'r') as docx_zip:\n",
    "        image_files = [f for f in docx_zip.namelist() if f.startswith(\"word/media/\")]\n",
    "        # os.makedirs(output_folder, exist_ok=True)\n",
    "        for image_file in image_files:\n",
    "            image_data = docx_zip.read(image_file)\n",
    "            image = Image.open(BytesIO(image_data))\n",
    "            images.append(image)\n",
    "            # image_filename = os.path.basename(image_file)\n",
    "            # with open(os.path.join(output_folder, image_filename), \"wb\") as img_out:\n",
    "            #     img_out.write(image_data)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "docx_path = \"/home/longquan/project/learning/LLM/docs/Spring Bulbs.docx\"\n",
    "output_dir = \"/home/longquan/project/learning/LLM/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = extract_text_with_docxreader(docx_path)\n",
    "images = extract_images_as_pil(docx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's Time To Plant Spring Bulbs\\n\\n\\n\\nSpectacular spring bulbs will brighten up your garden with their vibrant colour and delightful fragrance. Plant now in autumn to enjoy beautiful blooms once spring arrives. With a huge range of bulbs to choose from, you can create stunning displays in garden beds, borders, or pots.\\n\\nPlanting\\n\\nThe best time to plant spring bulbs is in autumn, but specific planting times vary depending on the variety. Check out our top varieties below for detailed tips, or ask a friendly team member instore if you’re unsure. Spring bulbs grow well in both garden beds and pots. When planting in the ground, ensure the soil is well-draining and nutrient rich. Mix in Kings Compost and pumice sand at planting time, or use a specialised mix like Tui Bulb Mix for best results. If your garden beds tend to get soggy during wetter months, plant your bulbs into a slight mound to improve drainage. For pots, choose a container large enough for the bulbs to grow into, and ensure it has adequate drainage holes. Plant directly into Tui Bulb Mix for the best results\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'Spring Bulbs.docx'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.PngImagePlugin.PngImageFile image mode=RGB size=749x422>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "textSplitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024, chunk_overlap=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'file_name': 'Spring Bulbs.docx'}, page_content=\"It's Time To Plant Spring Bulbs\\n\\n\\n\\nSpectacular spring bulbs will brighten up your garden with their vibrant colour and delightful fragrance. Plant now in autumn to enjoy beautiful blooms once spring arrives. With a huge range of bulbs to choose from, you can create stunning displays in garden beds, borders, or pots.\\n\\nPlanting\"),\n",
       " Document(metadata={'file_name': 'Spring Bulbs.docx'}, page_content='Planting\\n\\nThe best time to plant spring bulbs is in autumn, but specific planting times vary depending on the variety. Check out our top varieties below for detailed tips, or ask a friendly team member instore if you’re unsure. Spring bulbs grow well in both garden beds and pots. When planting in the ground, ensure the soil is well-draining and nutrient rich. Mix in Kings Compost and pumice sand at planting time, or use a specialised mix like Tui Bulb Mix for best results. If your garden beds tend to get soggy during wetter months, plant your bulbs into a slight mound to improve drainage. For pots, choose a container large enough for the bulbs to grow into, and ensure it has adequate drainage holes. Plant directly into Tui Bulb Mix for the best results')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks = textSplitter.split_documents(docs)\n",
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open_clip.list_pretrained()\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    'ViT-B-32', \n",
    "    pretrained='/home/longquan/model/CLIP-ViT-B-32-laion2B-s34B-b79K/open_clip_pytorch_model.bin', \n",
    "    load_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # model in train mode by default, impacts some models with BatchNorm or stochastic depth active\n",
    "tokenizer = open_clip.get_tokenizer('ViT-B-32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_2_vec(image_pil):\n",
    "    image = preprocess(image_pil).unsqueeze(0)\n",
    "    with torch.no_grad(), torch.autocast(\"cuda\"):\n",
    "        image_features = model.encode_image(image)\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor = torch.cat(\n",
    "    [pil_2_vec(image) for image in images], \n",
    "    dim=0\n",
    "    )\n",
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"It's Time To Plant Spring Bulbs\\n\\n\\n\\nSpectacular spring bulbs will brighten up your garden with their vibrant colour and delightful fragrance. Plant now in autumn to enjoy beautiful blooms once spring arrives. With a huge range of bulbs to choose from, you can create stunning displays in garden beds, borders, or pots.\\n\\nPlanting\",\n",
       " 'Planting\\n\\nThe best time to plant spring bulbs is in autumn, but specific planting times vary depending on the variety. Check out our top varieties below for detailed tips, or ask a friendly team member instore if you’re unsure. Spring bulbs grow well in both garden beds and pots. When planting in the ground, ensure the soil is well-draining and nutrient rich. Mix in Kings Compost and pumice sand at planting time, or use a specialised mix like Tui Bulb Mix for best results. If your garden beds tend to get soggy during wetter months, plant your bulbs into a slight mound to improve drainage. For pots, choose a container large enough for the bulbs to grow into, and ensure it has adequate drainage holes. Plant directly into Tui Bulb Mix for the best results']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [i.page_content for i in text_chunks]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 77])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_token = tokenizer(text)\n",
    "text_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_2_vec(text):\n",
    "    with torch.no_grad(), torch.autocast(\"cuda\"):\n",
    "        text_features = model.encode_text(text)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    return text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tensor = text_2_vec(text_token)\n",
    "text_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_args = {\n",
    "    \"uri\": \"./milvus_demo.db\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 你的向量（512维）\n",
    "clip_text_vector = text_2_vec(text_token).tolist()  # List[float]\n",
    "clip_image_vector = image_tensor.tolist()  # List[float]\n",
    "\n",
    "vectors = [clip_text_vector, clip_image_vector]  # List[List[float]]\n",
    "# metadatas = [\n",
    "#     {\"type\": \"text\", \"original\": \"A photo of a cat.\"},\n",
    "#     {\"type\": \"image\", \"path\": \"cat.jpg\"}\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_args = {'uri': './milvus_demo.db'}\n",
    "\n",
    "vector_store = MilvusClient(**connection_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"clip_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not vector_store.has_collection(collection_name):\n",
    "    vector_store.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vector_field_name=\"vector\",\n",
    "            dimension=512,\n",
    "            auto_id=True,\n",
    "            enable_dynamic_field=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'insert_count': 1, 'ids': [457250782843502598], 'cost': 0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 准备数据\n",
    "clip_image_vector = image_tensor.squeeze(0).tolist()  # List[float]\n",
    "data_image = {\n",
    "    \"vector\": clip_image_vector,  # 向量字段\n",
    "    \"type\": \"text\",              # 类型字段\n",
    "    \"filename\": \"cat.jpg\",    # 文件名字段(动态字段)\n",
    "}\n",
    "\n",
    "vector_store.insert(collection_name=collection_name, data=data_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_text_vector =  text_tensor  # torch.Size([2, 512])\n",
    "for vector in clip_text_vector:\n",
    "    data_text = {\n",
    "        \"vector\": vector,  # 向量字段\n",
    "        \"type\": \"text\",              # 类型字段\n",
    "        \"filename\": \"cat.jpg\",    # 文件名字段(动态字段)\n",
    "    }\n",
    "    vector_store.insert(collection_name=collection_name, data=data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymilvus.milvus_client.milvus_client.MilvusClient at 0x7fc829539150>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Image.open(\"/home/longquan/project/learning/LLM/images/image1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = preprocess(Image.open(\"/home/longquan/project/learning/LLM/images/08fdd9b671b1cf624289cc0fd7837b83.jpeg\")).unsqueeze(0)\n",
    "text = tokenizer([\"a sunflower\", \"a dog\", \"a flower\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 224, 224]), torch.Size([3, 77]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape, text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label probs: tensor([[9.9093e-01, 1.8791e-07, 9.0733e-03]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), torch.autocast(\"cuda\"):\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "print(\"Label probs:\", text_probs)  # prints: [[1., 0., 0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512]), torch.Size([3, 512]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features.shape, text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
